  # Default values for zitadel.

zitadel:
  zitadel:

  #https://github.com/zitadel/zitadel/issues/3598

    # Additional environment variables
    #env:
    #  - name: ZITADEL_DATABASE_POSTGRES_HOST
    #    value: stolon-proxy.stolon
    #  - name: ZITADEL_DATABASE_POSTGRES_PORT
    #    value: 5432
    #  - name: ZITADEL_DATABASE_POSTGRES_DATABASE
    #    valueFrom:
    #      secretKeyRef:
    #        name: postgres-zitadel
    #        key: database
    #  - name: ZITADEL_DATABASE_POSTGRES_USERNAME
    ##    valueFrom:
    #      secretKeyRef:
    #        name: postgres-zitadel
    #        key: username
    #  - name: ZITADEL_DATABASE_POSTGRES_PASSWORD
    #    valueFrom:
    #      secretKeyRef:
    #        name: postgres-zitadel
    #        key: password



    # The ZITADEL config under configmapConfig is written to a Kubernetes ConfigMap
    # See all defaults here:
    # https://github.com/zitadel/zitadel/blob/main/cmd/defaults.yaml
    image:
      tag: v2.11.0
    configmapConfig:
      ExternalDomain: auth.local.ertia.cloud
      ExternalSecure: true
      TLS:
        Enabled: false
      Database:
        cockroach:
          Enabled: false
          enabled: false
          User:
            SSL:
              Mode: disable
              RootCert:
              Cert:
              Key:
          Admin:
            SSL:
              Mode: disable
              RootCert:
              Cert:
              Key:
        postgres:
          Enabled: true
          MaxOpenConns: 25
          MaxConnLifetime: 1h
          MaxConnIdleTime: 5m
          Host: stolon-proxy.stolon
          Port: 5432
          Database: zitadel
          User:
            Username: zitadel
            Password: zitadel
            SSL:
              Mode: disable
              RootCert:
              Cert:
              Key:
          Admin:
            Username: postgres
            Password: postgres
            SSL:
              Mode: disable
              RootCert:
              Cert:
              Key:

      Machine:
        Identification:
          Hostname:
            Enabled: true
          Webhook:
            Enabled: false

    # The ZITADEL config under secretConfig is written to a Kubernetes Secret
    # See all defaults here:
    # https://github.com/zitadel/zitadel/blob/main/cmd/defaults.yaml
    secretConfig:

    # Reference the name of a secret that contains ZITADEL configuration.
    # The key should be named "config-yaml".
    configSecretName:

    # ZITADEL uses the masterkey for symmetric encryption.
    # You can generate it for example with tr -dc A-Za-z0-9 </dev/urandom | head -c 32
    masterkey: 'oce8qUe2WFgQACZq1gc3VP1JEnKmG6M6'
    # Reference the name of the secret that contains the masterkey. The key should be named "zitadel-masterkey".
    # Note: Eighter zitadel.masterkey or zitadel.masterkeySecretName must be set
    #masterkeySecretName: ""

    # The root CA Certificate needed for establishing secure database connections
    #dbSslRootCrt: ''

    # The Secret containing the root CA Certificate at key ca.crt needed for establishing secure database connections
    dbSslRootCrtSecret: ''

    # The Secret containing the client CA Certificate and key at tls.crt and tls.key needed for establishing secure database connections
    dbSslClientCrtSecret: ''

  replicaCount: 3

  image:
    repository: ghcr.io/zitadel/zitadel
    pullPolicy: IfNotPresent
    # Overrides the image tag whose default is the chart appVersion.
    tag: ""

  chownImage:
    repository: alpine
    pullPolicy: IfNotPresent
    tag: "3.11"

  imagePullSecrets: []
  nameOverride: ""
  fullnameOverride: ""

  serviceAccount:
    # Specifies whether a service account should be created
    create: true
    # Annotations to add to the service account
    annotations: {}
    # The name of the service account to use.
    # If not set and create is true, a name is generated using the fullname template
    name: ""

  podAnnotations: {}

  podSecurityContext:
    runAsNonRoot: true
    runAsUser: 1000

  securityContext: {}

  service:
    type: ClusterIP
    port: 8080
    protocol: http2
    annotations: {}

  
  ingress:
    enabled: true
    annotations:
      traefik.ingress.kubernetes.io/router.tls: 'true'
      kubernetes.io/ingress.class: traefik
      traefik.ingress.kubernetes.io/router.entrypoints: websecure
      #cert-manager.io/cluster-issuer: letsencrypt-production
      cert-manager.io/cluster-issuer: self-signed #mkcert
    hosts:
      - host: auth.local.ertia.cloud #git.@DOMAIN@
        paths:
          - path: /
            pathType: Prefix
    tls:
      - secretName: zitadel-tls
        hosts:
          - auth.local.ertia.cloud #git.@DOMAIN@            
          

  resources: {}

  nodeSelector: {}

  tolerations: []

  affinity: {}

  metrics:
    enabled: false
    serviceMonitor:

      # If true, the chart creates a ServiceMonitor that is compatible with Prometheus Operator
      # https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/api.md#monitoring.coreos.com/v1.ServiceMonitor.
      # The Prometheus community Helm chart installs this operator
      # https://github.com/prometheus-community/helm-charts/tree/main/charts/kube-prometheus-stack#kube-prometheus-stack
      enabled: false
      honorLabels: false
      honorTimestamps: true

  cockroachdb:
    enabled: false
    fullnameOverride: crdb
    tls:
      enabled: false



